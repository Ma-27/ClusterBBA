# 研究思路构建-2025.6.25

[Example.md](..\4-实验设计\Example.md)

## 在线质量函数簇驱动的BBA信息融合 ：

## <u>Online Mass function Clustering for Multi Source BBA information fusion</u>

## 整体研究思路

DST中的经典Dempster组合规则是一个**交换**且**结合**
的运算，它假定多源证据是相互独立且可信的。但问题在于，当证据高度冲突时，直接使用Dempster规则常会产生违反直觉的结果。Zadeh第一个指出了DST组合的悖论：例如，一个证据几乎完全支持命题$A$
，另一个证据几乎完全支持互斥命题$B$，==按照Dempster规则组合后可能会给出对某一命题较高的置信，明显不合理==。这种**证据冲突**
的问题引发了大量研究，形成了**两大类解决策略**：

- **修改或替代组合规则（“动配方”）**：直接调整组合公式本身，将冲突量以新的方式分配或处理，以避免异常结果。
- **修正原始证据（“洗原料”）**：在组合前先调整证据的BPA（例如折扣不可靠证据或平滑冲突），再使用标准组合规则，从源头上减轻冲突。

虽然说 BBA 的信息融合是顺序无关（交换结合）的，但是两大类解决思路中：

1. 修改组合规则大多数破坏了一些运算性质。而且不同组合规则有不同的使用场景，在不同场景下效果不好。该思路同样不符合刚刚所述的直觉——即，我们认为证据冲突的本质是
   **小部分BBA给出截然相反的判断**导致的。大部分修改组合规则的做法也削弱了多数BBA给出的判断。

2. 给证据带权，在上述案例中，这是符合直觉的做法。算权思路有两种：

    - 提出新散度，有 JS，BJS，FBJS 等一大类散度指标。核心思路是证据的可信度（权）是由其余 BBA 决定的。一个 BBA 离其他 BBA
      越远，则其可信度越小。难点是证明新散度符合度量属性。

    - 提出熵，证明其数理意义，但是最终算权通常还是要结合散度等其他度量，把熵包装进某度量公式。

我的思路是，既然有些证据相互支持，表现出相同的倾向，而有些冲突的证据表现出不同的倾向。那就可以建立不同的在线质量函数簇 (
Online Mass function Clusters) ，或者如果不强调支持在线添加 $m$ 的话，就是 质量函数簇（下面简称簇）。具有支持同一倾向的特征的
BBA 归类到一个簇中，支持不同倾向的特征的 BBA 归类到不同的簇中，是**基于 BBA 数据驱动**的分簇模式和算法。

为什么要建立这个东西呢？请看下面的例子。在证据融合中，如果考虑 BBA 与 BBA 的结构，会发现往往会因为各种依赖关系而呈现出某种类特征。

###### Example 3.1 最简单的非均匀分布 BPA 例子

| BPA       | $\theta_1$ | $\theta_2$ | $\Theta$ |
|-----------|------------|------------|----------|
| **$m_1$** | 0.9        | 0.1        | 0        |
| **$m_2$** | 0.85       | 0.15       | 0        |
| **$m_3$** | 0.1        | 0.9        | 0        |
| **$m_4$** | 0.25       | 0.25       | 0.5      |

**这里明显1,2具有一个簇的倾向，3具有1个簇的倾向，4具有一个簇的倾向。**

###### Example 3.2 稍微复杂的 BPA 例子

| BBAs  | $m(\{A\})$ | $m(\{B\})$ | $m(\{C\})$ | $m(\{A, C\})$ |
|-------|------------|------------|------------|---------------|
| $m_1$ | 0.40       | 0.29       | 0.30       | 0.01          |
| $m_2$ | 0.01       | 0.90       | 0.08       | 0.01          |
| $m_3$ | 0.58       | 0.07       | 0.01       | 0.34          |
| $m_4$ | 0.55       | 0.10       | 0.01       | 0.34          |
| $m_5$ | 0.60       | 0.10       | 0.01       | 0.29          |

> 注：表中的数值来自文献24

**这里，明显 1, 具有一个簇的倾向；2 具有一个簇的倾向，其余的 3,4,5 具有一个簇的倾向。**

因此，在DS理论中，从我的视角看，证据融合的本质是综合多个 BBA 给出一个融合后的 BBA。其本质也是将不合群的 $m$
（可能是数量较少的，未获得充分信息的观测；可能是欺诈的 BBA；可能是...）推走建立新的质量函数簇 。将具有相似信任的 BBA
放在一个质量函数簇中，融合后，通过计算簇权和簇内元素权，将权赋给 BBA 后融合 BBA，就可以使用经典DS理论的组合规则控制证据的冲突和分歧程度。

我想到了使用改证据熵（baseline可以是deng entropy），作为簇熵，衡量一个簇的信息量（模糊-冲突分解）；使用 BJS
改进的群divergence衡量簇与簇之间信息的重叠性（作为簇-簇散度）。这样融合结束就能得出几个簇了。每个簇的信息足够独特，分簇依据也可以使用散度衡量，分簇结果具有解释性。

建立簇后，根据簇的信息（比如簇熵和簇-簇散度）给簇内的 BBA 算权，使用经典 DS
证据理论融合。在簇-簇间信息可以综合考虑簇的规模，簇的信息熵，这样可以明确的看出哪些簇的信息对整体决策造成了巨大的贡献，哪些簇的信息有可能是噪声，算权时可以加上由专家给出的-专家偏见系数(
超参) $\alpha$ ，动态控制对大簇和小簇的相对信任程度。

~~而且，该算法和簇视角从本质上支持新的 BBA 融入簇中-只需要重新计算权重，大大降低了当新 BBA 涌入时，全局重算所有权的复杂度，所以可以是
Online 的~~。

该研究在信息融合上的意义并不特别显著，但是将相似的 BBA 集簇，量化了簇的信息量和簇间的冲突，推动了从证据做出决策的解释性。此外，由专家根据不同
BBA 案例情况和分簇情况指定专家偏见系数，有利于动态的控制从多大意义上应该相信偏见，提升了证据融合的灵活性和动态性。此外，该研究创新了
BBA 计算机制，推动了 BBA 在线融合的发展。

## 研究思路

把簇看做的表示信任分派的另一个基本单元（我们通常使用 BBA 来表示信任，但是没有把 BBA 归类到一起的表示法），由若干个 BBA
组成。例如，当将一个新的质量函数 $m_{1}$ 添加到已有的 $m_{2}$ 所构成的簇中时，初始簇可表示为一元簇 $\{m_{2}\}$
，添加后形成二元簇:  $Clus = \{m_1,m_2\}$ 簇就是把已经加入簇的 BBA 直接写成一个集合。

---

**设计簇的目的是刻画多个 BBA 加入进一个簇后，多个 BBA 互相的信任增强效应或信任冲突效应。**如下面的例子：

Example 3.3 [Example.md](..\4-实验设计\Example.md)

| BBAs  | $m(\{A\})$ | $m(\{AB\})$ | $m(\{B\})$ |
|-------|------------|-------------|------------|
| $m_1$ | 0.80       | 0.15        | 0.05       |
| $m_2$ | 0.90       | 0.10        | 0.00       |

verse，加入高冲突证据。

| BBAs  | $m(\{A\})$ | $m(\{AB\})$ | $m(\{B\})$ |
|-------|------------|-------------|------------|
| $m_3$ | 0.03       | 0.12        | 0.85       |

从直觉上来来看，$m_1$ 与 $m_2$ 给出了较为相似的判断，共同对于命题 $A$ 赋予较大的信任质量。而 $m_3$ 给出了与 $m_1$ 与 $m_2$
截然相反的判断，给命题 $B$ 赋予较大的信任质量，这就造成了证据 $m_3$ 与 $m_1$、$m_2$ 冲突。根据 ”相似的 BBA 应该被划归到同一个簇“
的设计初衷，$m_1$ 与 $m_2$ 应该被归类到一个簇，$m_3$ 应该自己成为一个簇。

因此，如果将 BBA 加入簇看做是一个序列运算，那么如果按照  $m_1$ ---> $m_2$   ---> $m_3$ 的顺序加入簇，在加入 $m_3$
时显然会影响簇的设计原则。当簇 $Clus_1 = \{m_1,m_2\}$ 时候，两个 BBA
可以视为相互增强的信念。而当如果 $'Clus_{1} = \{m_1, m_2, m_3\}$ 时，$m_3$ 的加入显然会极大的削弱簇 $Clus_1$ 持有的信念，也就引发了
BBA 的信任冲突，总有一些 BBA 因为不可信或者采样方式不同等原因，和大多数 BBA 给出的信念不一致，**因此明确的将 BBA
区分到持有不同信任信息的簇是必要的**。

Example 3.3 剩余的质量分配如下：

| BBAs  | $m(\{A\})$ | $m(\{AB\})$ | $m(\{B\})$ |
|-------|------------|-------------|------------|
| $m_4$ | 0.05       | 0.03        | 0.92       |
| $m_5$ | 0.87       | 0.11        | 0.02       |

其中，$m_1, m_2, m_5$ 应被划归为一个簇 $Clus_1$，$m_3, m_4$ 应被划归为一个簇 $Clus_2$。

---

#### 使用什么策略表示这个簇中的基本元素呢？

如果我们把每个 BBA 看作是一个分配在 $2^\Theta$ 上的集合，那么如果我们把簇定义一个和 BBA 有自相似性的结构（与 BBA
保持同样的 $2^\Theta$ 个命题结构）构造类似"平均 BBA"一样的东西，理论上就可以表征这个簇。设计簇的目的不仅仅是把 BBA
聚合在一起，这个结构必须描述**簇内部 BBA 相互的信任增强效应，簇间 BBA 的信任冲突效应**。换句话说，簇内的信息应该倾向于支持一种结论，不同的簇支持不同的结论。

我们根据簇-簇之间的距离/熵，与已经有的簇内距离/熵（普通的 belief entropy 和 BJS）就可以全面刻画一个 BBA 的权重。

当分簇结果出现后，由专家根据簇的结构指定，对于某簇应该赋予多少信任水平。

考虑使用分形结构来表示簇。这样表示法的优点有：

1. 这些BBA彼此都具有自相似性。利用分形可以揭示深层次的信任分派共性和差异。
2. 设计入簇机制，一个簇与一个BBA运算， 由于同阶分形的自相似性，因此一个 BBA 对一个已有簇的信任强化和信任削减效应也会非常明显。分形机制刻画了这一点。

## 下面给出一系列分形、簇定义

#### 定义 BBA

**BBA 基本定义 here,不再赘述。**

特别的，在 Dempster–Shafer 证据理论（DST）中，一组基本概率分配（BBA）可被视作一个序列
$$
\mathcal{M}=\{\,m_1,\,m_2,\,\dots,m_j,\dots,m_n\}
$$
证据融合问题可看做是，将这 $n$ 个 BBA 通过 Dempster 组合法则合成为一个新的 BBA $\widehat{m}^{\,}$。其中运算“$\oplus$”为
Dempster’s rule of combination。
$$
\overline{m}
\;=\;
m_1\;\oplus\;m_2\;\oplus\;\cdots\;\oplus\;m_n = \bigoplus_{j=1}^{K} m_j^{}
$$

对于这一组 BBA $\mathcal{M}$ 中的第 $j$ 个基本概率分配（BBA）记作
$$
m_j:\;2^\Theta\to[0,1],\quad \sum_{A\subseteq\Theta}m_j(A)=1
$$

#### 定义 均等分形运算 $F$ 与高阶分形BBA $m_{F_j}^{(h)}$

定义**均等分形运算 $F$**（或者记作 $Frac$ ）将原 BBA $m_j$ 中每个非空命题 $A_j\subseteq\Theta$ 的质量，平均分配到其所有非空真子集上：
$$
\boxed{\;
F\bigl(m_j\bigr (A_i))
=\sum_{\,A_k\supsetneq A_i}\frac{1}{2^{|A_k|}-1}\,m_j(A_k)
\qquad\forall A_i\subseteq\Theta,\;A_i\neq\varnothing
\;}
$$
其中，分母 $2^{|A_k|}-1$ 表示命题 $A_k$ 中所有非空子集的数量。

我们对原始的第 $j$ 个 BBA $m_j$ 在BBA $h$ 次分形下定义其**高阶分形质量函数 $m_{F_j}^{(h)}$**：
$$
\boxed{
m_{F_j}^{(h)} = F^h\bigl(m_j^{(0)}\bigr)
= \underbrace{F\bigl(F\bigl( \cdots F\bigl( m_j^{(0)} \bigr)\bigr)\bigr)}_{h\;\text{次}}
}
$$
其中，$h$ 被定义为**分形阶**（ $h\in\mathbb{N}^+$），代表了 BBA 被分形的次数。

除前述一次性展开式外，还可等价地给出**递归形式**：
$$
\begin{cases}
m_{F_j}^{(0)}=m_j,\\[6pt]
m_{F_j}^{(h)}=F\bigl(m_{F_j}^{(h-1)}\bigr),\quad h\in\mathbb{N}^+.
\end{cases}
$$
由此易得
$$
m_{F_j}^{(h)}
=F\bigl(m_{F_j}^{(h-1)}\bigr)
=F\bigl(F\bigl(\cdots F(m_j)\bigr)\bigr)
=F^h(m_j)
$$
与原定义完全等价。

**特别地**，当 $h=0$ 时，$m_{F_j}^0$ 不发生拆分，自然退化为第 $j$ 个 BBA $m_j$ ，约定
$$
m_{F_j}^{(0)}=m_j,\qquad F\bigl(\widetilde m^{\varnothing}_{F_i}\bigr) = \widetilde m^{\varnothing}_{F_i}
$$
对任意$h\in\mathbb{N}_0$（即$h=0,1,2,\dots$），由分形算子的定义可知
$$
m_{F_j}^{(h)}:2^\Theta\to[0,1],\qquad
\sum_{A\subseteq\Theta}m_{F_j}^{(h)}(A)=1
$$
并且对所有$A\subseteq\Theta$有
$$
m_{F_j}^{(h)}(A)\ge0
$$

---

根据这样的设计策略，分形不仅可以保持 BBA 之间的自相似性，而且，平均分形刻画了多元集质量减少，单元集合质量增多效应， 正好对应了BBA
相互的信任增强效应（文献证明了多次分形后 BBA
会退化为概率  [305-Higher order belief divergence with its application in pattern classification.pdf](..\..\..\书籍与文献\课题研究\质量函数簇驱动的证据融合\305-Higher order belief divergence with its application in pattern classification.pdf) ）

为了保证结果的可解释性和公理性，簇内元素必须是无序的，入簇运算必须是交换结合的运算。接下来定义簇的相关指标。

#### 定义 簇 $Clus_i$

设一组基本概率分配（BBA）为 $\mathcal M=\{\,m_j:2^\Theta\to[0,1]\mid j=1,2,\dots\}$，规定第 $i$ 个簇记作 $Clus_i$
，是 $\mathcal M$ 的任意BBA子集。具体定义为
$$
Clus_i=\bigl\{\,m_{1},\,m_{2},\,\dots,\,m_{n_i}\bigr\}\subseteq\mathcal M,\qquad n_i=|Clus_i|
$$
其中

- $n_i=|Clus_i|$ 表示簇 $i$ 中 BBA 的个数；

- 当 $n_i=0$ 时，约定 $Clus_i=\varnothing$ ，即“空簇”，表示该簇尚未接收任何 BBA；

- 簇为无序且不含重复元素的集合。

若对某一 BBA $m$ 有
$$
m\in Clus_i
$$
则表示该 BBA 已被分配到第 $i$ 个簇。

在上述“均等分形运算”与“高阶分形BBA”以及“簇”的基础上，我们可以将一个簇中所有BBA在同一分形阶 $h$
下的高阶分形质量函数取平均，得到簇的“簇心”（Cluster Fractal Centroid），即“簇分形平均
BBA”。这一结构不仅保留了每个BBA的自相似性，也反映了簇内各BBA的信任增强效应。

在此基础上，定义簇集 $\mathcal{C}= \{Clus_1,\dots,Clus_K\}$ 为对全集 $\mathcal{M}$ 的划分，满足
$$
\forall\,i\neq j:\;Clus_i\cap Clus_j=\varnothing
$$
且
$$
\bigcup_{i=1}^K Clus_i=\mathcal{M},
$$
==并且令 $K$ 等于所有包含至少一个 BBA 的簇的总数。==

#### 定义 簇分形平均 BBA（簇心） $\widetilde m^{(h)}_{F_i}$

设待融合 BBA 集合为 $\mathcal{M}=\{\,m_1,\,m_2,\,\dots,m_j,\dots,m_n\}$，第 $i$ 个簇记为
$$
Clus_i=\{m_{j}\mid j=1,2,\dots ,n_i\}\subseteq\mathcal M,\qquad n_i=|Clus_i|\ge 1
$$
对簇中每个 BBA $m_j$，在固定分形阶 $h\in\mathbb N_0$ 下得到其高阶分形形式 $m^{(h)}_{F_j}$（见前述均等分形运算 $F$
定义）。将这些同阶分形 BBA 在命题空间 $2^{\Theta}$ 上逐点求算术平均，可得簇的分形平均 BBA（亦称“簇心”）
$$
\boxed{\;
\widetilde m^{(h)}_{F_i}(A)
=\frac{1}{n_i}\sum_{j=1}^{n_i} m^{(h)}_{F_j}(A),
\quad\forall A\subseteq\Theta
\;}
$$
显然
$$
\sum_{A\subseteq\Theta}\widetilde m^{(h)}_{F_i}(A)=1,\qquad  
\widetilde m^{(h)}_{F_i}(A)\ge 0
$$
故 $\widetilde m^{(h)}_{F_i}$ 本身是合法 BBA。

==为保持簇尺度与分形尺度的一致性，需要根据簇中元素数量统一分型尺度==，设约束条件
$$
h=n_i-1
$$
即 $h$ 随簇内元素数目递增并且保持线性映射关系：单元素簇对应分形阶 $h=0$，双元素簇对应分形阶 $h=1$，以此类推。当 $n_i=1$ 时有
$$
\widetilde m^{(0)}_{F_i}=m^{(0)}_{F_j}=m_j
$$
簇心的值退化为簇内唯一的原始 BBA。若后续有新的 BBA $m_{\text{new}}$ 并入 $Clus_i$，只需将
$$
n_i\leftarrow n_i+1,\qquad h\leftarrow h+1,\qquad Clus_i \leftarrow m_{new}
$$
**==注意簇分型平均BBA $\widetilde m^{(h)}_{F_i}$ 与 高阶分形BBA $m_{F_j}^{(h)}$ 的区别：前者专门用于簇，后者专门用于 BBA
分形。前者的上面带一个 $\widetilde m^{}$ 波浪线号。前者的 $i$ 代表第 的 $i$ 个簇，后者的 $j$ 代表当前要入簇的第 $j$ 个
BBA。==**

## BBA 加入簇的过程

上文中，**簇分形平均 BBA（簇心） $\widetilde m^{(h)}_{F_i}$ 定义**具备 **“BBA插入先后次序不影响簇心更新结果、簇心始终是合法的
BBA”** 这两条性质。但是上述 $\widetilde m^{(h)}_{F_i}$ 定义是通过平均数的方式来定义的，难以将 $\widetilde m^{(h)}_{F_i}$
的定义用在工程实现上。下面给出一个$\widetilde m^{(h)}_{F_i}$ 的递归定义，把 BBA 入簇定义为**动态的递推过程**。可证明两个定义
**完全等价**。

在进入更新公式之前，先给出一个新的“加权平均”算符定义，使得后文可直接用 $\cup$ 来表示“簇心”和新增分形 BBA 之间的加权平均：

###### 定义 加权平均算符 $\cup$ 与 $\widetilde m^{(h)}_{F_i}$ 的递推定义

令 $p,q:2^\Theta\to[0,1]$ 为任意两条 BBA（或簇心与新增元素的高阶分形 BBA），$n_i\in\mathbb{N}$ 为当前簇中原有元素个数。定义二元运算
$$
(p\;\cup\;q)(A)=\frac{n_i\,p(A)+q(A)}{n_i+1},\quad \forall A\subseteq\Theta
$$
显然，$(p\cup q)$ 仍是合法 BBA，且当 $n_i=1$ 时退化为简单平均。

有了上述符号之后，簇心的在线更新可统一为对任意分形阶 $h\ge1$：
$$
\widetilde{m}^{(h)}_{F_i}=F\bigl(\widetilde{m}^{(h-1)}_{F_i}\bigr)\cup m^{(h)}_{F_{j}}\;
$$
其中 $m^{(h)}_{F_j}$ 为第 $j$ 个新加入 BBA $m_j$ 在分形阶 $h$ 下的高阶分形 BBA。

等价地，通过递推定义 $\widetilde m^{(h)}_{F_i}$ ：
$$
\boxed{
\widetilde{m}^{(h)}_{F_i}(A)
=\bigl(F(\widetilde{m}^{(h-1)}_{F_i})\cup m^{(h)}_{F_{j}}\bigr)(A)
=\frac{n_i\,F\bigl(\widetilde{m}^{(h-1)}_{F_i}\bigr)(A)+m^{(h)}_{F_{j}}(A)}{n_i+1}
\quad\forall A\subseteq\Theta
}
$$
特别地，当 $h=0$ 时，退化为单元素簇心的初始定义：
$$
\widetilde{m}^{(0)}_{F_i}=m_j^{(0)}=m_j.
$$
该更新式保持了聚合过程的交换性与结合性。若为占位需要，可将空簇的簇心记作形式符号 $\widetilde m^{\varnothing}_{F_i}$
，它没有数值意义；一旦首个 BBA 加入，上述 $n_i=1$ 的退化情形即自动生效，不再保留占位符。

---

###### **证明两种 $\widetilde{m}^{(h)}_{F_i}(A)$ 定义的等价性**

证明：设第 $i$ 个簇当前含有 $n$ 条 BBA，记为
$$
Clus_i=\{m_1,m_2,\dots,m_n\},\qquad n\ge1,\qquad h=n-1
$$
欲证
$$
\widetilde m_{F_i}^{(h)}(A)=\dfrac1n\sum_{j=1}^{n}m_{F_j}^{(h)}(A)
,\qquad\forall A\subseteq\Theta \tag{★}
$$

> **注**：两侧分别由递归更新公式与算术平均公式给出；
>
> $F$ 仅需满足线性性 $F(\lambda p+\mu q)=\lambda F(p)+\mu F(q)$；

**Ⅰ 基线情形 $n=1$**

此时 $h=0$。递归定义与平均定义都退化为唯一的 $m_1$，故 (★) 成立。

**Ⅱ 归纳假设**

设当簇规模为 $k\,(k\ge1)$ 时，(★) 成立，即
$$
\widetilde m_{F_i}^{(k-1)}(A)=\frac1k\sum_{j=1}^{k}m_{F_j}^{(k-1)}(A) \tag{IH}
$$
**Ⅲ 归纳步**

向簇中再加入一条新 BBA $m_{k+1}$ 后，规模变为 $k+1$，分形阶随之增为 $h=k$。递归更新给出
$$
\widetilde m_{F_i}^{(k)}(A)=\frac{k\,F\!\bigl(\widetilde m_{F_i}^{(k-1)}\bigr)(A)+m_{F_{k+1}}^{(k)}(A)}{k+1} \tag{1}
$$
由归纳假设结合 $F$ 的线性性得到
$$
F\!\bigl(\widetilde m_{F_i}^{(k-1)}\bigr)(A)
=F\!\Bigl( \frac1k\sum_{j=1}^{k}m_{F_j}^{(k-1)} \Bigr)(A)
=\frac1k\sum_{j=1}^{k}F\!\bigl(m_{F_j}^{(k-1)}\bigr)(A)
=\frac1k\sum_{j=1}^{k}m_{F_j}^{(k)}(A) \tag{2}
$$
将 (2) 代入 (1) 可得
$$
\widetilde m_{F_i}^{(k)}(A)
=\frac{k\cdot\frac1k\sum_{j=1}^{k}m_{F_j}^{(k)}(A)+m_{F_{k+1}}^{(k)}(A)}{k+1}
=\frac1{k+1}\sum_{j=1}^{k+1}m_{F_j}^{(k)}(A)
$$
即 (★) 对 $n=k+1$ 成立。

由数学归纳法，(★) 对所有 $n\ge1$ 成立。两种 $\widetilde m_{F_i}^{(h)}(A)$ 的定义因此完全等价，==且等价性与所选分形算子 $F$
的具体形式无关，只依赖其线性性==。证毕。

---

#### Example 3.3 作为数值示例

从直觉上看，$m_1,m_2,m_5$ 同属“支持 $A$”一派，而 $m_3,m_4$ 则共同“支持 $B$”。下面沿着 **“分形-加权平均”在线更新规则**
，按 $m_1\!\rightarrow\!m_2\!\rightarrow\!m_3\!\rightarrow\!m_4\!\rightarrow\!m_5$ 的时序逐一入簇并计算实时簇心。

**(0) 初始状态**
$$
Clus_i = {\varnothing},\qquad \widetilde m^{(\varnothing)}_{F_i}\;=\;\varnothing,\qquad i=1,2.
$$
当首次有 BBA 加入时，立即生成新簇并将其簇心阶数置为 0。

**(1) 将 $m_1$ 并入 $Clus_1$**

先求 $m_1$ 的零阶分形 $m^{(0)}_{F_1}=F(m_1)=m_1$。
$$
\widetilde m^{(0)}_{F_1}=m_1=(0.80,\,0.15,\,0.05)
$$
再用加权平均算符 $\cup$ 更新簇心
$$
\widetilde m^{(0)}_{F_1}
=F(m^{(\varnothing)}_{F_1})\cup m^{(0)}_{F_1}
=\frac{0\cdot F(m^{(\varnothing)}_{F_1})+1\cdot m^{(0)}_{F_1}}{0+1}
=(0.80,\,0.15,\,0.05)
\qquad Clus_1=\{m_1\}
$$
**(2) 将 $m_2$ 并入 $Clus_1$**

先求 $m_2$ 的一阶分形 $m^{(1)}_{F_2}=F(m_2)$：
$$
m^{(1)}_{F_2}=(0.9333,\,0.0333,\,0.0333)
$$
再用加权平均算符 $\cup$ 更新簇心
$$
\widetilde m^{(1)}_{F_1}
=F(\widetilde m^{(0)}_{F_1})\cup m^{(1)}_{F_2}
=\frac{1\cdot F\bigl(\widetilde m^{(0)}_{F_1}\bigr)+1\cdot m^{(1)}_{F_2}}{1+1}
=(0.8917,\,0.0417,\,0.0667)
\qquad Clus_1=\{m_1,m_2\}
$$

**(3) 将 $m_3$ 并入 $Clus_2$**

先求 $m_3$ 的零阶分形 $m^{(0)}_{F_3}=F(m_3)=m_3$。
$$
\widetilde m^{(0)}_{F_3}=m_3=(0.03,\,0.12,\,0.85)
$$
再用加权平均算符 $\cup$ 更新簇心
$$
\widetilde m^{(0)}_{F_2}
=F(m^{(\varnothing)}_{F_2})\cup m^{(0)}_{F_3}
=\frac{0\cdot F(m^{(\varnothing)}_{F_2})+1\cdot m^{(0)}_{F_3}}{0+1}
=(0.03,\,0.12,\,0.85)
\qquad Clus_2=\{m_3\}
$$
**(4) 将 $m_4$ 并入 $Clus_2$**

先对现簇心做一次同步分形
$$
F\!\bigl(\widetilde m^{(0)}_{F_2}\bigr)
=(0.0700,\,0.0400,\,0.8900)
$$
再求 $m_4$ 的一阶分形
$$
m^{(1)}_{F_4}=F(m_4)=(0.0600,\,0.0100,\,0.9300)
$$
由于并入前 $n_2=1$，按
$$
\widetilde m^{(1)}_{F_2}
=\frac{1\cdot F\!\bigl(\widetilde m^{(0)}_{F_2}\bigr)+1\cdot m^{(1)}_{F_4}}{1+1}
$$
得
$$
\;\widetilde m^{(1)}_{F_2}=(0.0650,\,0.0250,\,0.9100)\;
\qquad Clus_2=\{m_3,m_4\}
$$
**(5) 将 $m_5$ 并入 $Clus_1$**

此时 $n_1=2\Rightarrow h=2$。

对现簇心做一次同步分形
$$
F\!\bigl(\widetilde m^{(1)}_{F_1}\bigr)
=(0.9056,\,0.0139,\,0.0806)
$$
求 $m_5$ 的二阶分形
$$
m^{(2)}_{F_5}=F^{2}(m_5)=(0.9189,\,0.0122,\,0.0689)
$$
加权平均更新簇心
$$
\widetilde m^{(2)}_{F_1}
=\frac{2\cdot F\!\bigl(\widetilde m^{(1)}_{F_1}\bigr)+m^{(2)}_{F_5}}{2+1}
=(0.9100,\,0.0133,\,0.0767)
\qquad Clus_1=\{m_1,m_2,m_5\}
$$
综上，基于 **分形-加权平均在线簇心公式**
$$
\widetilde m^{(h)}_{F_i} = F\!\bigl(\widetilde m^{(h-1)}_{F_i}\bigr)\cup m^{(h)}_{F_j}, \qquad h=n_i-1
$$

本例得到两大簇及其最终簇心：

$$
\boxed{\; Clus_1=\{m_1,m_2,m_5\}, \quad \widetilde m^{(2)}_{F_1}=(0.9100,\,0.0133,\,0.0767) \;}
$$

$$
\boxed{\; Clus_2=\{m_3,m_4\}, \quad \widetilde m^{(1)}_{F_2}=(0.0650,\,0.0250,\,0.9100) \;}
$$

两簇分别强烈支持命题 $A$ 与 $B$，极好地展示了 **“同源增强、异源分离”** 的设计初衷，也验证了前述递推定义与算术平均定义的完全等价性。

## 研究思路（BBA入簇选择与折扣BBA）

我们已经设计了基本的簇定义和分形定义。

#### 表示基本元素后，如何设计一系列度量呢？

我们的直觉是，簇在加入新BBA $m_{new}$ 后，信念应该增强。因此描述一个簇的 deng熵
应该降低。反应在散度上（比如老师发过的 [A new divergence measure for basic probability assignment and its applications in extremely uncertain environments.pdf](..\..\..\书籍与文献\课题研究\Liguo Fei Related Works\A new divergence measure for basic probability assignment and its applications in extremely uncertain environments.pdf)
和BJS，其实簇内部的散度（divergence）应该相对低，簇间的divergence应该更高。

因此，我会把重点是散度的设计。当设计散度后，使用熵等信息论标准来评价簇的信息量。

#### 根据设计的度量，如何判别 $m_{new}$ 入哪个簇or不入现有的任何一个簇，另立新簇 $Clus_{i+1}$?

###### **思路1**：

比较所有的 簇心  $\widetilde m^{(h)}_{F_i}$ 与 $F^{h}(m_{new})$
的BJS散度（需要对齐到同阶），是否达到并超过需要分簇的距离阈值 $\tau$（$\tau$ 自己给定）；如果存在多于或等于一个簇 $Clus_i$
未超过 $\tau$，则选定最小的未超过 $\tau$ 的 $Clus_i$，将 $m_{new}$ 加入该簇。否则另立新簇。

###### **思路2**：

计算所有簇之间的两两距离，以及 $m_{new}$ 与各簇的距离，联合优化，以使**簇内距离最小（信息最一致）、簇间距离最大（信息差异明显）
**。即问题转换为，将BBA分入到哪个簇，可使如下比值最大化？
$$
k^\ast = \arg\max_k\frac{\sum_{} (簇-簇距离)/归一化}{归一化簇内距离}
$$
因此，表示簇内整体的距离，可以使用归一化的**簇内散度**；表示簇间距离，可使用**簇-簇散度**来衡量。

具体的优化方案为：

我们把 $m_{new}$ 到底该分到哪个簇的问题看做是 $K+1$ 个策略（ $K$ 是前文定义的簇总数量）。
$$
\begin{aligned}
Strategy_1: &\quad m_{\mathrm{new}}\longrightarrow Clus_{1}\\
Strategy_2: &\quad m_{\mathrm{new}}\longrightarrow Clus_{2}\\
&\;\;\vdots\\
Strategy_K: &\quad m_{\mathrm{new}}\longrightarrow Clus_{K}\\
Strategy_{K+1}: &\quad m_{\mathrm{new}}\longrightarrow Clus_{K+1}\;(\text{New Cluster})
\end{aligned}
$$
针对每一条候选策略，我们计算上面的式子的比值，当这个式子取最大值时的策略 $k^\ast$。

目前有两个候选公式 A 与 B。两个公式在是否考虑多簇归一化上面有争议。

$$
k^\ast = \arg\max_k \frac{\sum_{} (簇-簇散度)/归一化}{\sum_{} ({簇}_k内BBA散度)/归一化}\tag{A}
$$

$$
k^* \;=\;\arg\max_{k}
\frac{\displaystyle
\sum\bigl(\text{簇–簇散度}\bigr)\,/\,\text{归一化}}
{\displaystyle
\sum\bigl(\sum_{} ({簇}_k内BBA散度)/归一化)\,/\,\text{归一化}}
\tag{B}
$$

总体来看，这个思路把选簇问题看做是贪心最优化问题，没有人为设定阈值，因此显得很有新意。而且计算出来的分母在迭代过程中具有可比性；同时，这个思路也量化了
“将一个BBA分进某个簇的收益” ，**为决策提供了数值依据**。

这个思路需要引入假设前提：当一个簇内只有1个 BBA 时，该簇内部的BBA平均值被设定为其簇内BBA的平均值；当只有一个簇时，簇-簇散度被设定为
1。

==**考虑了一下后，选用思路2继续进行研究**==

#### 分簇完成后，如何使用簇的信息，融合专家对簇的看法（专家偏见系数），计算最终的折扣BBA呢？

## 簇内散度（Intra-cluster Divergence）

为了满足度量簇内部信息集中程度的目标，散度和熵都可以用作参考指标。从直觉上来看，簇内信息越一致，那么 BBA
之间的平均divergence就会低，BBA的平均熵也会低。但是由于熵主要考量单个 BBA
的信息量特性，即便两个BBA都低熵，我们仍然无法判断两个BBA是否高冲突，因此簇内多个BBA的信息集中程度应该基于两两比较。因此，我们使用平均
BJS 作为基本思路，衡量簇内部所有 BBA 的两两平均距离，作为簇内信息集中程度的度量。

设当前经过分簇得到的簇集为
$$
\begin{aligned}
\mathcal{C}
&= \{\,Clus_{1},\,Clus_{2},\,\dots,\,Clus_{K}\}, \\[6pt]
Clus_{i}
&= \bigl\{\,m_{1},\,m_{2},\,\dots,\,m_{p},\,\dots,\,m_{q},\,\dots,\,m_{n_{i}}\bigr\}
\subseteq \mathcal{M}, \\[6pt]
n_{i}
&= \lvert Clus_{i}\rvert.
\end{aligned}
$$
其中 $\mathcal M$ 为所有待融合的 BBA 集合，$Clus_i\subseteq\mathcal M$ 包含 $n_i$ 个元素 $\{m_{1},m_{2},\dots,m_{n_i}\}$
，每个 $m_j\colon2^{\Theta}\to[0,1]$ 都是一条 BBA，$K$ 为非空簇的总数。

#### 定义 簇内散度 $D_{intra}(Clus_i)$

我们把 Belief Jensen–Shannon (BJS) 散度作为衡量 BBA 之间差异度的基本度量。在保证交换性与结合性的前提下，**簇内散度**定义为同簇
BBA 两两 BJS 的算术均值，并对簇规模为 1 的情形作补偿性处理：
$$
\boxed{
D_{\mathrm{intra}}(Clus_i)\;=\;
\begin{cases}
\dfrac{2}{n_i(n_i-1)}\displaystyle\sum_{1\le p<q\le n_i}
\operatorname{BJS}\!\bigl(m_{p},m_{q}\bigr)
& n_i\ge 2\\[15pt]
\dfrac{1}{K-1}\displaystyle\sum_{\substack{j=1\\j\neq i}}^{K}
D_{\mathrm{intra}}(Clus_j)
& n_i=1,\;K\ge 2
\end{cases}
}
$$

- **一般情形 $n_i\ge2$**式中系数 $\frac{2}{n_i(n_i-1)}$ 保证所有 $C_{n_i}^2$ 条 BBA-BBA divergence被等权计入；一个簇内若所有
  BBA 完全一致，则每一项 BJS = 0，故 $D_{\mathrm{intra}}\!\left(Clus_i\right)=0$，与“簇内无冲突”直觉一致。

- **单元素簇且 $K\ge2$**簇内只有一条“自环”，BJS 恒为 0，会在后续 $\tfrac{\text{簇间散度}}{D_{\mathrm{intra}}}$
  指标中导致分母过小而失真．因此让其取代价——其它簇平均簇内散度——可视为“**用整体平均来替代估计该簇内部一致性的期望水平**”。
- **全局只有一簇（$K=1$) 且 $n_i=1$**此极端场景下已无法利用参照簇，全局也只有一个BBA，这没有比较意义 (
  BJS也必须是两个BBA才能计算距离）。在后续 BBA 入簇的时候会直接跳过这个情况。

上述定义满足：

- **非负性**BJS∈[0,1] ⇒$D_{\mathrm{intra}}\ge0$。
- **一致性极值**BBA 完全一致 ⇒ all BJS = 0 ⇒$D_{\mathrm{intra}}=0$。
- **规模不敏感**在保持簇成员间两两 BJS 不变的情况下，向簇内复制任意 BBA 不会改变 $D_{\mathrm{intra}}$；这与“散度度量关注*
  *差异结构**而非样本出现次数”的理念一致。

## **簇-簇 Jensen–Shannon 散度（Cluster-to-Cluster Jensen–Shannon Divergence, CCJS）**

为了度量不同簇的信息差异程度，同样需要一种divergence来度量差异程度。但是，需要注意簇心通过分形，被映射到了不同的阶（相当于是不同的尺度），直接在不同尺度上做divregence显然不满足度量公理，因此需要将簇-簇的分形尺度都统一到一个阶上面。目前有三种统一的办法，即
① 统一到最大分形阶 ② 统一到最小分形阶 ③ 统一到平均分形阶，这是在未来具有研究价值的问题。因为可解释性和理论自洽的原因，我暂时选择
① 。这样，即便簇位于不同的分形阶，统一到最大阶也使它们可比。

设 $\Theta$ 为命题集，$2^{\Theta}$ 为其幂集。对全部基本概率分配（BBA）的分簇结果记为
$$
\mathcal{C} = \bigl\{\mathrm{Clus}_1,\dots,\mathrm{Clus}_p,\dots,\mathrm{Clus}_q,\dots,\mathrm{Clus}_K\bigr\}
$$

#### 定义 全局最大分形阶 $H$

为了消除不同簇心处于不同分形阶所导致的不可比性，引入**全局最大分形阶**
$$
H \;\equiv\;\max_{1\le i\le K}h_i
$$
对任意两簇 $\mathrm{Clus}_p$、$\mathrm{Clus}_q$，其分形阶分别 $h_p,h_q$，令
$$
\widehat m_{F_p}^{(H)}
=F^{\,H-h_p}\!\bigl(\widetilde m_{F_p}^{(h_p)}\bigr),
\quad
\widehat m_{F_q}^{(H)}
=F^{\,H-h_q}\!\bigl(\widetilde m_{F_q}^{(h_q)}\bigr)
$$
则 $\widehat m_{F_p}^{(H)}$ 与 $\widehat m_{F_q}^{(H)}$ 均位于同一阶 $H$，可直接进行散度度量。

> 我的灵感来源是，当一个一个 BBA 加入簇后，它总对某些焦元（这些焦元共 $2^\Theta - 1$
>
个）有强化效应，并不是所有的BBA在每个焦元上都有均等的质量分配。因此，当我们观察一群BBA时，就好像每个BBA是一个选民，若一组选民如果集中对某些焦元“投了票”，另一组选民为不同的一些焦元“投了票”，那么，在簇-簇散度中应该反应这种差异。

因此，最自然的做法是，为每个焦元 $A$ 定义**规模权重 $w_p$、$w_q$**：
$$
w_p(A)
=\frac{\bigl|\{\,m_i\in\mathrm{Clus}_p:\,m_i(A)>0\}\bigr|}
{\displaystyle\sum_{B\subseteq\Theta}\bigl|\{\,m_i\in\mathrm{Clus}_p:\,m_i(B)>0\}\bigr|}\,,\qquad
w_q(A)
=\frac{\bigl|\{\,m_j\in\mathrm{Clus}_q:\,m_j(A)>0\}\bigr|}
{\displaystyle\sum_{B\subseteq\Theta}\bigl|\{\,m_j\in\mathrm{Clus}_q:\,m_j(B)>0\}\bigr|}\,
$$
其中，$\lvert S\rvert$ 表示集合 $S$ 中元素的个数。在这里 $\{\,m_i\in\mathrm{Clus}_p:\,m_i(A)>0\}$ 是“簇 $p$
中所有对焦元 $A$ 赋予正质量的 BBA 的集合”，有多少 其实就是 (簇 $q$ 在焦元 $A$ 上分配质量的BBA个数) / 簇 $q$
在所有焦元中分配质量的BBA总个数。

对于一个簇而言， $\sum_{A\subseteq\Theta}w_p(A)=1$ 且 $\sum_{A\subseteq\Theta}w_q(A)=1$，权重 $w$ 总会落在 $[0,1]$ 之间。

==注意规模权重 $w$ 是用簇内原始的 BBA $m_i$ 计算的，而不是利用簇心计算的。簇心分形后 $2^{\Theta}-1$
个集合都会有点质量，因此不能用簇心定义 $w$。==

#### 定义 簇-簇 Jensen–Shannon 散度 $D_{CCJS}$

对任意两簇 $\mathrm{Clus}_p$、$\mathrm{Clus}_q$，其分形阶分别 $h_p,h_q$，则两个簇的簇分形平均
BBA（簇心）分别是 $\widetilde m^{(h_p)}_{F_p}$ 和 $\widetilde m^{(h_q)}_{F_q}$
。我们使用簇心代表两簇 $\mathrm{Clus}_p$、$\mathrm{Clus}_q$ 计算簇-簇 Jensen–Shannon 散度（**下文简称簇-簇散度**）。

仿照 B 散度，簇-簇散度 $D_{CCJS}$ 定义为 加权 Jensen–Shannon 形式：
$$
M(A)=\frac{1}{2}\,\widehat m_{F_p}^{(H)}(A)+\frac{1}{2}\,\widehat m_{F_q}^{(H)}(A)
$$

$$
D_{\mathrm{CCJS}}\!\bigl(\mathrm{Clus}_p,\mathrm{Clus}_q\bigr) \equiv
D_{\mathrm{CCJS}}\!\bigl(\widetilde m^{(h_p)}_{F_p},\widetilde m^{(h_q)}_{F_q}\bigr)=
\sum_{A\subseteq\Theta}
w_p\,
\widehat m_{F_p}^{(H)}(A)\,
\log_2\frac{\widehat m_{F_p}^{(H)}(A)}{M(A)}
\;+\;
\sum_{A\subseteq\Theta}
w_q\,
\widehat m_{F_q}^{(H)}(A)\,
\log_2\frac{\widehat m_{F_q}^{(H)}(A)}{M(A)}
$$
虽然 $D_{CCJS}$ 是一个合法的**散度(divergence)**，但 $D_{CCJS}$ 绝对不是一个合法的**度量(metric)**，因为其不满足三角不等式，有如下反例。

> **反例设定**
>
> - 三个二元分布：
>
> $$
> P=[0.9,0.1],\quad Q=[0.5,0.5],\quad R=[0.1,0.9].
> $$
>
> - 对应簇规模：
>
> $$
> n_P=1,\quad n_Q=2,\quad n_R=3.
> $$
>

以下表格汇总了各对的散度与距离：

| Pairs | $D$ (散度) | $d$ (距离) |
|-------|----------|----------|
| P–Q   | 0.1041   | 0.3226   |
| Q–R   | 0.1133   | 0.3366   |
| P–R   | 0.4552   | 0.6747   |

（三角不等式左、右侧值）

- **散度**：
  $$
  D(P,R)=0.4552,\quad D(P,Q)+D(Q,R)=0.1041+0.1133=0.2174,
  $$
  明显 $0.4552 > 0.2174$，三角不等式 $D(P,R)\le D(P,Q)+D(Q,R)$ 被打破。

- **距离**：
  $$
  d(P,R)=0.6747,\quad d(P,Q)+d(Q,R)=0.3226+0.3366=0.6593,
  $$
  也有 $0.6747 > 0.6593$，三角不等式同样不成立。

这个数值实验清楚地表明：

1. 未开根号的 CCJS 散度 $D$ 已经违背了三角不等式，无法作为度量；
2. 即便对其开根号得到 $d=\sqrt{D}$，也**不能**恢复三角不等式。

因此，这个带规模权重 CCJS 定义在一般情况下只能算是一种**对称有界散度**，并不满足“真正的度量”（metric）要求。

#### 定义 增强簇-簇 Jensen–Shannon 散度 $RD_{CCJS}$

我们希望把原本的加权 JS 散度直接变成两个向量之间的欧氏距离，以便一开头就自动满足三角不等式。为此，我们给每个簇 $Clus_p$
在每个焦元 $A\subseteq\Theta$ 上都分配一个**特征**
$$
\Phi_A(Clus_p)=\sqrt{\,w_p(A)\,\widehat m_{F_p}^{(H)}(A)\,}\!
$$
也就是说，$w_p(A)$ 就是簇 $p$ 在焦元 $A$ 上的总质量占簇 $p$ 上所有焦元质量之和的比重，$\widehat m_{F_p}^{(H)}(A)$
是分形迭代后簇心在 $A$ 上的平均质量。这样，簇 $p$ 和簇 $q$ 在每个焦元上的差异就对应为两者特征之差，所有焦元上的差异平方和
$$
\sum_{A\subseteq\Theta}\bigl(\Phi_A(Clus_p)-\Phi_A(Clus_q)\bigr)^2
$$
该平方和是一种新的、与 JS 散度不同的加权 Hellinger 散度。最终将其开根号，就得到
$$
RD_{CCJS}(Clus_p,Clus_q)
=\sqrt{\sum_{A\subseteq\Theta}\Bigl(\sqrt{w_p(A)\,\widehat m_{F_p}^{(H)}(A)}-\sqrt{w_q(A)\,\widehat m_{F_q}^{(H)}(A)}\Bigr)^2}\,
$$
这样一来，簇间距离就被视为高维空间中两点的欧氏距离，**非负性、对称性及三角不等式**都自然而然地成立。

尽管 $RD_{CCJS}$
不是严格意义上的度量（它是一个伪度量，因为证明自反性失败）——它允许不同簇之间出现“零距离”，但是簇与簇的距离仍然可以被一致的量化比较，在度量上，$RD_{CCJS}$
确实比 $D_{CCJS}$ 散度更加优秀。

###### 证明非负性：

显然根号下平方和非负。

###### 证明对称性

证明目标是关于簇 $p$ 和 $q$ 的对称性，即需验证
$$
RD_{CCJS}(Clus_p,Clus_q)
=RD_{CCJS}(Clus_q,Clus_p).
$$
我们从定义出发：
$$
RD_{CCJS}(Clus_q,Clus_p)
=\sqrt{
\sum_{A\subseteq\Theta}
\Bigl(
\sqrt{w_q(A)\,\widehat m_{F_q}^{(H)}(A)}
-\sqrt{w_p(A)\,\widehat m_{F_p}^{(H)}(A)}
\Bigr)^2
}.
$$
利用实数的平方性质 $\bigl(x-y\bigr)^2=\bigl(y-x\bigr)^2$，将被开方的和式中每一项变换：
$$
\begin{align}
\Bigl(
\sqrt{w_q(A)\,\widehat m_{F_q}^{(H)}(A)}
-\sqrt{w_p(A)\,\widehat m_{F_p}^{(H)}(A)}
\Bigr)^2
&=
\Bigl(
-\bigl[\sqrt{w_p(A)\,\widehat m_{F_p}^{(H)}(A)}
-\sqrt{w_q(A)\,\widehat m_{F_q}^{(H)}(A)}\bigr]
\Bigr)^2 \\
&=
\Bigl(
\sqrt{w_p(A)\,\widehat m_{F_p}^{(H)}(A)}
-\sqrt{w_q(A)\,\widehat m_{F_q}^{(H)}(A)}
\Bigr)^2.
\end{align}
$$
将此恒等带回原式中，可得
$$
RD_{CCJS}(Clus_q,Clus_p)
=\sqrt{
\sum_{A\subseteq\Theta}
\Bigl(
\sqrt{w_p(A)\,\widehat m_{F_p}^{(H)}(A)}
-\sqrt{w_q(A)\,\widehat m_{F_q}^{(H)}(A)}
\Bigr)^2
}
=RD_{CCJS}(Clus_p,Clus_q).
$$
因此，$RD_{CCJS}$ 关于簇索引的对称性得证。

###### 证明三角不等式

我们先把增强后的簇–簇距离写成坐标形式，对每个焦元 $A$ 定义三个簇 $Clus_p$，$Clus_q$，$Clus_r$ 的特征
$$
p_A = \sqrt{\,w_p(A)\,\widehat m^{(H)}_{F_p}(A)}\,,\qquad
q_A = \sqrt{\,w_q(A)\,\widehat m^{(H)}_{F_q}(A)}\,,\qquad
r_A = \sqrt{\,w_r(A)\,\widehat m^{(H)}_{F_r}(A)}\,.
$$
于是
$$
RD_{CCJS}(p,q)
=\sqrt{\sum_A (p_A - q_A)^2},\quad
RD_{CCJS}(q,r)
=\sqrt{\sum_A (q_A - r_A)^2},\quad
RD_{CCJS}(p,r)
=\sqrt{\sum_A (p_A - r_A)^2}.
$$
（下文中，$RD_{CCJS}(Clus_p,Clus_q)$ 使用  $RD_{CCJS}(p,q)$ 这样类似的符号代指）

接下来，我们一步步证明三角不等式
$$
RD_{CCJS}(p,r)\;\le\;RD_{CCJS}(p,q)\;+\;RD_{CCJS}(q,r).
$$
首先，利用一维数轴上的三角不等式，对每个焦元 $A$ 都有
$$
\bigl|\,p_A - r_A\bigr|
\;\le\;
\bigl|\,p_A - q_A\bigr|
\;+\;
\bigl|\,q_A - r_A\bigr|.
$$
对所有焦元求和得
$$
\sum_A\bigl|p_A - r_A\bigr|
\;\le\;
\sum_A\bigl|p_A - q_A\bigr|
\;+\;
\sum_A\bigl|q_A - r_A\bigr|.
$$
其次，注意对任意实数列 $\{x_i\}$ 有
$$
\sqrt{\sum_i x_i^2}
\;\le\;
\sum_i\bigl|x_i\bigr|,
$$
因为
$$
\Bigl(\sum_i |x_i|\Bigr)^2
=\sum_i x_i^2+2\sum_{i<j}|x_i||x_j|
\;\ge\;\sum_i x_i^2.
$$
于是
$$
RD_{CCJS}(p,r)
=\sqrt{\sum_A(p_A - r_A)^2}
\;\le\;
\sum_A\bigl|p_A - r_A\bigr|
\;\le\;
\sum_A\bigl|p_A - q_A\bigr|
\;+\;
\sum_A\bigl|q_A - r_A\bigr|.
$$
最后，再次运用同样的“平方和小于绝对值之和”不等式，对两项分别下界：
$$
\sum_A\bigl|p_A - q_A\bigr|
\;\ge\;
\sqrt{\sum_A (p_A - q_A)^2}
\;=\;RD_{CCJS}(p,q),
$$
将这些串联，就得到
$$
RD_{CCJS}(p,r)
\;\le\;
\sum_A\bigl|p_A - q_A\bigr|
\;+\;
\sum_A\bigl|q_A - r_A\bigr|
\;\le\;
RD_{CCJS}(p,q)\;+\;RD_{CCJS}(q,r).
$$
至此，增强后的距离函数 $RD_{CCJS}$ 在逐维应用一维三角不等式与“平方和不超过绝对值之和”的基本事实后，便自然满足三角不等式。

###### 证明自身的度量为0

根据我们对 $RD_{CCJS}$ 的定义：
$$
RD_{CCJS}(Clus_p,Clus_q)
=\sqrt{\sum_{A\subseteq\Theta}
\Bigl(\sqrt{w_p(A)\,\widehat m_{F_p}^{(H)}(A)}
-\sqrt{w_q(A)\,\widehat m_{F_q}^{(H)}(A)}\Bigr)^2}\,
$$
当我们取同一簇 $p=q$ 时，权重与簇心质量完全相同，即对每个焦元 $A$ 都有
$$
w_p(A)=w_q(A),\quad
\widehat m_{F_p}^{(H)}(A)=\widehat m_{F_q}^{(H)}(A)
$$
因此在求和式中，每一项的被开方表达式都变成
$$
\Bigl(\sqrt{w_p(A)\,\widehat m_{F_p}^{(H)}(A)}
-\sqrt{w_p(A)\,\widehat m_{F_p}^{(H)}(A)}\Bigr)^2
=\bigl(0\bigr)^2=0
$$
将这些零项相加，得到根号内总和为 0，进而
$$
RD_{CCJS}(Clus_p,Clus_p)
=\sqrt{0}=0
$$
也就是说 $RD_{CCJS}$ 度量了每个簇与自身的距离恰好为零。

###### 证明 $RD_{CCJS}$ 自反性 （失败，说明 $RD_{CCJS}$ 只可以单向计算，过程不可逆）

[RD_CCJS证明自反性失败.md](RD_CCJS证明自反性失败.md)

## BBA 选簇的过程（Cluster-Driven Admission Rule）

承接思路2，在本节中，我们给出一个严谨可复现的 **BBA 入簇机制**，其核心是以 **簇-簇散度** 与 **簇内散度**
的比值为准则，判定一条待加入的基本概率分配（BBA） $m_{\mathrm{new}}$ 应归属到哪个现有簇 $Clus_i$ 还是另起新簇 $Clus_{i+1}$
。思路的本质是“簇内距离最小化、簇间距离最大化”，从而表示不同簇的信息独特性。

#### 定义 策略

承接上述所有定义，设当前已有簇集 $\mathcal C=\{Clus_1,\dots,Clus_K\}$，待进入簇的 BBA 为 $m_{\mathrm{new}}$
。将 $m_{\mathrm{new}}$ 的入簇问题视作可执行的 $K+1$ 种策略，BBA 应该归属于哪个 $Clus_i$
还是建立新簇的问题可视为，使用下面的方法选择一个最优策略 $k$ 。
$$
\bigl\{\mathrm{Strategy}_k\bigr\}_{k=1}^{K+1},
\qquad
\begin{aligned}
\mathrm{Strategy}_k &: m_{\mathrm{new}}\rightarrow Clus_k, & 1\le k\le K,\\
\mathrm{Strategy}_{K+1} &: m_{\mathrm{new}}\rightarrow Clus_{K+1}\ (\text{new cluster}). &
\end{aligned}
$$
对每一个策略 $k$，构造临时簇 $Clus_k^{+}$（ $m_{\mathrm{new}}$ 并入 $Clus_k$）或当 $k=K+1$ 时候，为 $m_{\text{new}}$
新建临时簇 $Clus_k^{+}$。

记策略执行后的簇总数为 $K_k$（若新建簇则 $K_k=K+1$，并入旧簇则 $K_k=K$）。相应的，共有 $P_k=\frac{K_k\,(K_k-1)}{2}$
个簇的两两距离对。数学化的表述是：
$$
P_k=\frac{K_k(K_k-1)}{2},\qquad
Clus_k^{+}=
\begin{cases}
Clus_k\cup\{m_{\mathrm{new}}\}, & k\le K,\\[2pt]
\{m_{\mathrm{new}}\}, & k=K+1.
\end{cases}
$$

#### 定义 选簇收益 $\mathcal R_k$

在上述入簇机制中，我们将策略 $k$ 的选簇收益定义为一个“簇间／簇内”比 $\mathcal R_k$，即：
$$
\boxed{
R_k \;=\;
\frac{\displaystyle
\frac{1}{P_k}\sum_{1\le i<j\le K_k}D_{\mathrm{CCJS}}\bigl(Clus_i,Clus_j\bigr)}
{\displaystyle
\frac{1}{K_k}\,D_{\mathrm{intra}}\bigl(Clus_k^{+}\bigr)}
\tag{Reward}
}
$$
其中

- 分子是 **所有簇的平均簇-簇散度**，用 $P_k$ 归一化两两 $D_{\mathrm{CCJS}}$ 之和；
- 分母是 **归一化簇内散度**，把含 $m_{\mathrm{new}}$ 的簇内散度按簇数 $K_k$ 平均；
- $D_{\mathrm{CCJS}}$ 与 $D_{\mathrm{intra}}$ 的具体定义如前所述。

最终，我们通过最大化此收益函数来确定最优归属簇：
$$
\boxed{
k^{\ast} \;=\;\arg\max_{k\in\{1,\dots,K+1\}}\;R_k
}
$$
由此，$R_k$既量化了在策略 $k$ 下全局信息的“可分性”，又兼顾了局部簇内的一致性水平，取最大者即为最优的入簇方案。

###### 数理意义与边界处理

公式 $R_k$ 用分子衡量“在策略 $k$ 下全局平均簇-簇离散度”，再以分母描述"将 $m_{\text{new}}$
置于该簇后，所有簇的平均簇内离散度”。比值越大则策略 $k$ 更优。

若某阶段仅有 **一个簇**（$K=1$，尚无法计算簇-簇散度），则约定 $\overline D_{\text{CCJS}}^{(k)}\equiv1$ 。保证 $R_k$
有定义且首个新簇有数值稳定性。若 $Clus_k^{+}$ 中仅含一条 BBA 致 $D_{\mathrm{intra}}=0$，则这种情况会被直接跳过，因为这种情况下分母也会为
0，对单元素-单簇计算收益没有意义（$R_k$并不是距离度量，不满足度量公理的同一性）。

---

#### Example 3.3 作为数值示例，演示选簇决策过程

最初的五条 BBA $m_1 \sim m_5$ 如上表所述。基于高阶均等分形＋加权平均的在线更新公式，算法首先得到两大簇及其簇心
$$
Clus_1=\{m_1,m_2,m_5\},\;\widetilde m_{F_1}^{(2)}=(0.9100,\,0.0133,\,0.0767) \qquad Clus_2=\{m_3,m_4\},\;\widetilde m_{F_2}^{(1)}=(0.0650,\,0.0250,\,0.9100)
$$
这里分形阶数 $h_i=n_i-1$ 与簇规模严格对齐，因此 $\widetilde m_{F_1}^{(2)}$ 和 $\widetilde m_{F_2}^{(1)}$ 均是合法
BBA，而两簇恰好分别强化了命题 $A$ 与 $B$。

当一条新 BBA $m_{\text{new}}$ 到来时，算法把它放入 $K$ 个已有簇或单独成簇，共 $K+1$ 种 Strategy$_k$。针对每个 Strategy$_k$
，计算

其中分子是**簇-簇散度**之和，分母是**归一化簇内散度**，两者都基于同阶分形 $H=\max_i h_i$。得分越高说明“簇间越分离、簇内越紧凑”，Strategy
越优。

###### 场景 1：把 $m_6=(0.95,0.03,0.02)$ 插入现有双簇

|         | Strategy 1 → Clus₁ | Strategy 2 → Clus₂ | Strategy 3 → 新 Clus₃ |
|---------|--------------------|--------------------|----------------------|
| 高阶 A 公式 | **28.3946**        | 0.5017             | 21.8159              |
| 低阶 A 公式 | **29.0135**        | 0.5017             | 24.8458              |
| 高阶 B 公式 | **27.5304**        | 0.9728             | 21.8159              |
| 低阶 B 公式 | **28.1300**        | 0.9728             | 24.8358              |

四组打分一致推断：$m_6$ 应加入 Clus₁。这与直觉吻合——$m_6$ 几乎纯支持 $A$，与 Clus₁ 的信念方向完全同向，而放入 Clus₂
或单开新簇都会显著降低簇间可分性。

###### 场景 2：把 $m_7=(0.25,0.50,0.25)$（最大熵 BBA）插入

|             | Strategy 1 → Clus₁ | Strategy 2 → Clus₂ | Strategy 3 → 新 Clus₃  |
|-------------|--------------------|--------------------|-----------------------|
| 高阶 A / 低阶 A | 2.7974 / 2.9888    | 1.7852 / 1.7852    | **16.0199 / 22.0597** |
| 高阶 B / 低阶 B | 4.8265 / 5.2102    | 3.3333 / 3.3333    | **16.0199 / 22.0597** |

均衡 BBA 同时远离两簇的主流观点，单独成簇 Clus₃ 可把簇-簇散度大幅推高，因此 Strategy 3 被各公式一致选中。算法成功捕捉“最大熵=高不确定性=自成一派”的语义。

###### 场景 3：早期只有 Clus₁={m₁,m₂} 时向其中插入冲突 $m_3$

此时只有两种策略。评分

\text{Join Clus₁}=2.0551,\qquad \text{New Clus₂}=19.6071\sim22.7695 \]:contentReference[oaicite:3]
{index=3}，高维低维两对公式结果相同，说明 $m_3$ 与 Clus₁ 冲突极强，必须开辟新簇，亦验证了散度比值的灵敏性。 #### 场景
4：仅有 $m_1$ 时插入高度相似的 $m_2$ 当簇里只含 $m_1$，策略比较给出 \[ \text{Join Clus₁}=32.4675\gg0.0308=\text{New
Clus₂} \]:contentReference[oaicite:4]{index=4}。分形加权平均几乎等于把 $m_2$ 叠加到
Clus₁，显著压低簇内散度并抬升簇-簇散度，因此合并最优。 --- 上述四次实验完整展示了**分形-簇心-散度**
框架如何在不同情形下给出一致且可解释的入簇决策： * 同源 BBA → 自动汇入原簇； * 强冲突 BBA → 自动分裂新簇； * 中等相似度
BBA → 依据综合打分在“并入 or 新簇”间权衡。 所有计算均遵循线性分形运算 $F$、分形阶一致化 $H$ 以及 CCJS
散度，使得簇心更新与策略评分二者皆满足交换、结合与可扩展性，为后续在线大规模证据融合奠定了可复现的数值基础。

## 融合系数计算与融合算法

// 公式： 某个 BBA 的可信权重 = (簇内距离等指标)^alfa x （簇间距离或者簇熵）^beta ,其中，alfa和beta是有关联的专家超参。

## 如何进行证据融合？

算法分为两步。第一步将 BBA 纳入到簇中，并且更新簇的信息。第二步根据簇的信息折扣 BBA 的权重。

#### 将 BBA 纳入簇中

1. **初始化**

   将第一条基本概率分配 $m_1$ 单独置入新簇 $\mathrm{Clus}_1$，并令当前簇集
   $$
   \mathcal C = \{\mathrm{Clus}_1\}.
   $$

2. **逐条插入剩余 BBA**
   对于第 $i$ 条 $m_{\mathrm{new}} = m_i$（$i=2,\dots,N$）依次处理：

    1. 令当前簇数为 $K = |\mathcal C|$。

    2. 枚举 $k=1,\dots,K$ 对应 “合并进已有簇 $\mathrm{Clus}_k$” 和 $k=K+1$ 对应“另起新簇”两类共 $K+1$ 种策略：

        - 若选第 $k\le K$ 种，则在 $\mathrm{Clus}_k$ 中加入 $m_{\mathrm{new}}$；
        - 若选第 $K+1$ 种，则新建簇 $Clus_{K+1}=\{m_{\mathrm{new}}\}$。

    3. 依次遍历每种策略，对每种策略构造的簇集 $\mathcal C_k$：

        - 计算簇集 $\mathcal C_k$ 中簇的最大分形阶 $H$，把所有簇心都对齐到最高阶  $\widehat m_{F_j}^{(H)}$

        - 计算**两两簇–簇散度** $D_{DCC}(Clus_p,Clus_q)$，其中若 $K_k=1$ 则约定 $D_{\mathrm{CCJS}}=1$。

        - 遍历每个簇，计算**归一化簇内散度 $D_{intra}(Clus_i)$** 。

          若 $\overline{D}_{\mathrm{intra}}=0$（只有单元素簇且唯一簇）则跳过该策略。

        - 组合成**收益** $\mathcal R_k$。

    4. 选择使 $R_k$最大的策略 $k^*$。

    5. 按 $k^*$ 策略更新 $\mathcal C$，对应的簇和簇心。

3. **输出**
   返回最终选择的簇集 $\mathcal C$ 及其各簇心 $\widetilde m_{F_i}^{(h_i)}$。

###### 复杂度简要分析

单步插入 $m_i$ 时，若当前簇数为 $K$，则需评估 $K+1$ 种策略，每种策略：

- 平均簇–簇散度代价约 $\mathcal O(K^2\cdot|2^\Theta|)$；借助缓存和单步增量更新可降至 $\mathcal O(K\cdot|2^\Theta|)$。
- 簇内散度更新代价约 $\mathcal O(n_k^2)$，增量维护后仅需 $\mathcal O(n_k)$。因此，第 $i$ 步总体时间可近似视为

$$
\mathcal O\bigl(K\cdot|2^\Theta| + n_{k^*}\bigr),
$$

最坏情形 $K\!\approx\!i$、$n_{k^*}\!\approx\!i$ 为 $\mathcal O(i)$，但在 $K\ll i$
的聚类场景中远优于线性。空间开销主要来自簇对散度缓存 $\mathcal O(K^2)$ 及存储所有 BBA $\sum_k n_k=i$
。GPU并行和阈值粗筛（先排除收益过低的簇，再精评）可进一步提升效率。

#### 根据簇折扣证据，计算权重

## 结论与讨论

本研究的贡献有

-

但是还存在以下问题：

- 计算两两簇-簇散度时，每次都要额外计算，而不能利用已有的簇心。原因是分形后每个簇的簇心各处于不同的分形阶，尺度不同，量纲不统一，不可强行比较。
- 统一策略的数理性质是在未来具有研究价值的问题。比如所提出的 ① 统一到最大分形阶 ② 统一到最小分形阶 ③
  统一到平均分形阶，不同策略，在加入BBA后的退化特性，最大信息量，分形尺度等 is still an open issue。
- **阶对齐或多尺度融合**的问题，值得后续深入研究。
- 由于采用贪心策略，故在不同的 BBA 加入顺序中，不能从理论上保证，重复试验的分簇结果稳定（算法稳定性，即重复不能100%保证复现结果完全一致）。





